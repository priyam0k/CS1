<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Linear Regression | Actuarial Statistics (Priyam’s Fork)</title>
  <meta name="description" content="A modified version of the book on actuarial statistics, with additional notes and examples." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Linear Regression | Actuarial Statistics (Priyam’s Fork)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A modified version of the book on actuarial statistics, with additional notes and examples." />
  <meta name="github-repo" content="priyam0k/CS1" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Linear Regression | Actuarial Statistics (Priyam’s Fork)" />
  
  <meta name="twitter:description" content="A modified version of the book on actuarial statistics, with additional notes and examples." />
  

<meta name="author" content="Priyam" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="goodness-of-fit.html"/>
<link rel="next" href="generalised-linear-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Actuarial Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#motivation"><i class="fa fa-check"></i>Motivation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="r-setup.html"><a href="r-setup.html"><i class="fa fa-check"></i><b>1</b> R Setup</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-setup.html"><a href="r-setup.html#preparing-your-environment-for-r"><i class="fa fa-check"></i><b>1.1</b> Preparing your environment for <code>R</code></a></li>
<li class="chapter" data-level="1.2" data-path="r-setup.html"><a href="r-setup.html#basic-interations-with-r"><i class="fa fa-check"></i><b>1.2</b> Basic interations with <code>R</code></a></li>
<li class="chapter" data-level="1.3" data-path="r-setup.html"><a href="r-setup.html#functions-in-r"><i class="fa fa-check"></i><b>1.3</b> Functions in <code>R</code></a></li>
<li class="chapter" data-level="1.4" data-path="r-setup.html"><a href="r-setup.html#data-structures-in-r"><i class="fa fa-check"></i><b>1.4</b> Data structures in <code>R</code></a>
<ul>
<li class="chapter" data-level="" data-path="r-setup.html"><a href="r-setup.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
<li class="chapter" data-level="" data-path="r-setup.html"><a href="r-setup.html#dataframes"><i class="fa fa-check"></i>Dataframes</a></li>
<li class="chapter" data-level="" data-path="r-setup.html"><a href="r-setup.html#lists"><i class="fa fa-check"></i>Lists</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-setup.html"><a href="r-setup.html#logical-expressions-in-r"><i class="fa fa-check"></i><b>1.5</b> Logical expressions in <code>R</code></a></li>
<li class="chapter" data-level="1.6" data-path="r-setup.html"><a href="r-setup.html#extending-r-with-packages"><i class="fa fa-check"></i><b>1.6</b> Extending <code>R</code> with packages</a></li>
<li class="chapter" data-level="1.7" data-path="r-setup.html"><a href="r-setup.html#importing-data"><i class="fa fa-check"></i><b>1.7</b> Importing data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#objectives-discrete-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#theory-discrete-distributions"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="2.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#in-built-probability-distributions"><i class="fa fa-check"></i><b>2.1</b> In-built probability distributions</a></li>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-probability-distributions-covered"><i class="fa fa-check"></i>Discrete probability distributions covered</a></li>
<li class="chapter" data-level="2.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>2.2</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>2.3</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.4" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>2.4</b> Negative binomial distribution</a></li>
<li class="chapter" data-level="2.5" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>2.5</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="2.6" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>2.6</b> Poisson distribution</a></li>
<li class="chapter" data-level="2.7" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-uniform"><i class="fa fa-check"></i><b>2.7</b> Uniform distribution</a></li>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#practice-discrete-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Continuous Probability Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#objectives-continuous-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#theory-continuous-distributions"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="3.1" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#in-built-probability-distributions-1"><i class="fa fa-check"></i><b>3.1</b> In-built probability distributions</a></li>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#continuous-probability-distributions-covered"><i class="fa fa-check"></i>Continuous probability distributions covered</a></li>
<li class="chapter" data-level="3.2" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>3.2</b> Normal distribution</a></li>
<li class="chapter" data-level="3.3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#lognormal-distribution"><i class="fa fa-check"></i><b>3.3</b> Lognormal distribution</a></li>
<li class="chapter" data-level="3.4" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>3.4</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.5" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>3.5</b> Gamma distribution</a></li>
<li class="chapter" data-level="3.6" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6</b> <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="3.7" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>3.7</b> Student’s <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="3.8" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#f-distribution"><i class="fa fa-check"></i><b>3.8</b> <span class="math inline">\(F\)</span> distribution</a></li>
<li class="chapter" data-level="3.9" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>3.9</b> Beta distribution</a></li>
<li class="chapter" data-level="3.10" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#continuous-uniform"><i class="fa fa-check"></i><b>3.10</b> Uniform distribution</a></li>
<li class="chapter" data-level="3.11" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#inverse-transform-method"><i class="fa fa-check"></i><b>3.11</b> Inverse transform method</a></li>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#practice-continuous-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html"><i class="fa fa-check"></i><b>4</b> Joint and Conditional Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#objectives-joint-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#theory-joint-distributions"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#definition-and-representation"><i class="fa fa-check"></i><b>4.0.1</b> 1. Definition and Representation</a></li>
<li class="chapter" data-level="4.0.2" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#marginal-and-conditional-distributions"><i class="fa fa-check"></i><b>4.0.2</b> 2. Marginal and Conditional Distributions</a></li>
<li class="chapter" data-level="4.0.3" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#independence-of-random-variables"><i class="fa fa-check"></i><b>4.0.3</b> 3. Independence of Random Variables</a></li>
<li class="chapter" data-level="4.0.4" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#expectation-covariance-and-correlation"><i class="fa fa-check"></i><b>4.0.4</b> 4. Expectation, Covariance, and Correlation</a></li>
<li class="chapter" data-level="4.0.5" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#linear-combinations-and-sums-of-random-variables"><i class="fa fa-check"></i><b>4.0.5</b> 5. Linear Combinations and Sums of Random Variables</a></li>
<li class="chapter" data-level="4.0.6" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#practical-applications"><i class="fa fa-check"></i><b>4.0.6</b> 6. Practical Applications</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#practice-joint-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>5</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#objectives-clt"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#theory-clt"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#practice-clt"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-analysis.html"><a href="data-analysis.html"><i class="fa fa-check"></i><b>6</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="data-analysis.html"><a href="data-analysis.html#objectives-data-analysis"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="data-analysis.html"><a href="data-analysis.html#theory-data-analysis"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="6.0.1" data-path="data-analysis.html"><a href="data-analysis.html#definition-and-purpose"><i class="fa fa-check"></i><b>6.0.1</b> 1. Definition and Purpose</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-analysis.html"><a href="data-analysis.html#practice-data-analysis"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>7</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#objectives-exploratory-data-analysis"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#theory-exploratory-data-analysis"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#practice-exploratory-data-analysis"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="random-sampling.html"><a href="random-sampling.html"><i class="fa fa-check"></i><b>8</b> Random Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="random-sampling.html"><a href="random-sampling.html#objectives-random-sampling"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="random-sampling.html"><a href="random-sampling.html#theory-random-sampling"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="random-sampling.html"><a href="random-sampling.html#practice-random-sampling"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html"><i class="fa fa-check"></i><b>9</b> Estimation and estimators</a>
<ul>
<li class="chapter" data-level="" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html#objectives-estimators"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html#theory-estimators"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html#practice-estimators"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#objectives-confidence-intervals"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#theory-confidence-intervals"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#practice-confidence-intervals"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#objectives-hypothesis-testing"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#theory-hypothesis-testing"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-hypothesis-testing"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html"><i class="fa fa-check"></i><b>12</b> Goodness of Fit</a>
<ul>
<li class="chapter" data-level="" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#objectives-goodness-of-fit"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#theory-goodness-of-fit"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#practice-goodness-of-fit"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>13</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#objectives-linear-regression"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#theory-linear-regression"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#practice-linear-regression"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html"><i class="fa fa-check"></i><b>14</b> Generalised Linear Models</a>
<ul>
<li class="chapter" data-level="" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#objectives-glm"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#theory-glm"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#practice-glm"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>15</b> Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#objectives-bayesian-stats"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#theory-bayesian-stats"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#practice-bayesian-stats"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="divider"></li>
<li>Adapted by <a href="https://github.com/priyam0k">Priyam</a> from the original by <a href="https://github.com/agarbiak" target="blank">Alex Garbiak</a>.</li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Actuarial Statistics (Priyam’s Fork)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-regression" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Chapter 13</span> Linear Regression<a href="linear-regression.html#linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objectives-linear-regression" class="section level2 unnumbered hasAnchor">
<h2>Learning Objectives<a href="linear-regression.html#objectives-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Explain what is meant by response and explanatory variables.</li>
<li>State the simple regression model (with a single explanatory variable).</li>
<li>Derive the least squares estimates of the slope and intercept parameters in a simple linear regression model.</li>
<li>Use <code>R</code> to fit a simple linear regression model to a data set and interpret the output.</li>
</ol>
<ul>
<li>Perform statistical inference on the slope parameter.</li>
<li>Describe the use of measures of goodness of fit of a linear regression model.</li>
<li>Use a fitted linear relationship to predict a mean response or an individual response with confidence limits.</li>
<li>Use residuals to check the suitability and validity of a linear regression model.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>State the multiple linear regression model (with several explanatory variables).</li>
<li>Use <code>R</code> to fit a multiple linear regression model to a data set and interpret the output.</li>
<li>Use measures of model fit to select an appropriate set of explanatory variables.</li>
</ol>
</div>
<div id="theory-linear-regression" class="section level2 unnumbered hasAnchor">
<h2>Theory<a href="linear-regression.html#theory-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Chapter: Linear Regression</p>
<p>This chapter delves into quantifying and modelling relationships between variables, specifically focusing on linear associations. You’ll learn how to construct, fit, and assess linear regression models.</p>
<div id="learning-objective-1-explain-what-is-meant-by-response-and-explanatory-variables." class="section level4 hasAnchor" number="13.0.0.1">
<h4><span class="header-section-number">13.0.0.1</span> <strong>Learning Objective 1: Explain what is meant by response and explanatory variables.</strong><a href="linear-regression.html#learning-objective-1-explain-what-is-meant-by-response-and-explanatory-variables." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Response Variable (Y):</strong> This is the variable whose values are thought to depend on, or be explained by, another variable [CS1 Summary, Q3, 421]. It is the outcome or dependent variable in the model [CS1 CMP 2023.pdf, 139].</li>
<li><strong>Explanatory Variable (X):</strong> This is the variable that is thought to influence or explain the values of the response variable [CS1 Summary, Q3, 421]. It is also known as the predictor or independent variable [CS1 CMP 2023.pdf, 139]. Ideally, its values are under the experimenter’s control [CS1 Summary, Q3, 421-422].</li>
</ul>
</div>
<div id="learning-objective-2-state-the-simple-regression-model-with-a-single-explanatory-variable." class="section level4 hasAnchor" number="13.0.0.2">
<h4><span class="header-section-number">13.0.0.2</span> <strong>Learning Objective 2: State the simple regression model (with a single explanatory variable).</strong><a href="linear-regression.html#learning-objective-2-state-the-simple-regression-model-with-a-single-explanatory-variable." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The simple linear regression model describes the relationship between a single response variable (Y) and a single explanatory variable (X) [CS1 Summary, Q1, 419].</p>
<ul>
<li><strong>Model Equation:</strong> <span class="math inline">\(Y_i = \alpha + \beta X_i + \epsilon_i\)</span> [CS1 Summary, Q1, 419].
<ul>
<li><span class="math inline">\(Y_i\)</span>: The <span class="math inline">\(i\)</span>-th observation of the response variable [CS1 Summary, Q1, 419].</li>
<li><span class="math inline">\(X_i\)</span>: The <span class="math inline">\(i\)</span>-th observation of the explanatory variable [CS1 Summary, Q1, 419].</li>
<li><span class="math inline">\(\alpha\)</span>: The intercept parameter (the expected value of Y when X is 0) [CS1 Summary, Q5, 424].</li>
<li><span class="math inline">\(\beta\)</span>: The slope parameter (the expected change in Y for a one-unit increase in X) [CS1 Summary, Q5, 424].</li>
<li><span class="math inline">\(\epsilon_i\)</span>: The error term for the <span class="math inline">\(i\)</span>-th observation [CS1 Summary, Q1, 420].</li>
</ul></li>
<li><strong>Assumptions (Basic Model):</strong>
<ul>
<li>Errors (<span class="math inline">\(\epsilon_i\)</span>) are uncorrelated [CS1 Summary, Q1, 420].</li>
<li>Expected value of errors: <span class="math inline">\(E[\epsilon_i] = 0\)</span> [CS1 Summary, Q1, 420].</li>
<li>Constant variance of errors: <span class="math inline">\(Var(\epsilon_i) = \sigma^2\)</span> [CS1 Summary, Q1, 420].</li>
</ul></li>
<li><strong>Full Normal Model:</strong> In addition to the basic assumptions:
<ul>
<li>Errors (<span class="math inline">\(\epsilon_i\)</span>) are independent and normally distributed: <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span> [CS1 Summary, Q1, 420].</li>
<li>Consequently, <span class="math inline">\(Y_i \sim N(\alpha + \beta X_i, \sigma^2)\)</span> [CS1 Summary, Q1, 420].</li>
</ul></li>
</ul>
</div>
<div id="learning-objective-3-derive-the-least-squares-estimates-of-the-slope-and-intercept-parameters-in-a-simple-linear-regression-model." class="section level4 hasAnchor" number="13.0.0.3">
<h4><span class="header-section-number">13.0.0.3</span> <strong>Learning Objective 3: Derive the least squares estimates of the slope and intercept parameters in a simple linear regression model.</strong><a href="linear-regression.html#learning-objective-3-derive-the-least-squares-estimates-of-the-slope-and-intercept-parameters-in-a-simple-linear-regression-model." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <strong>least squares method</strong> aims to find the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> that minimise the sum of squared residuals (errors) [CS1 Summary, Q4, 422].
* <strong>Objective:</strong> Minimise <span class="math inline">\(\sum \epsilon_i^2 = \sum (Y_i - \alpha - \beta X_i)^2\)</span> [CS1 Summary, Q4, 422].
* <strong>Derivation Steps:</strong>
1. Differentiate the sum of squared errors with respect to <span class="math inline">\(\alpha\)</span> and set the partial derivative to zero [CS1 Summary, Q4, 422].
2. Differentiate the sum of squared errors with respect to <span class="math inline">\(\beta\)</span> and set the partial derivative to zero [CS1 Summary, Q4, 422].
3. Solve the resulting two equations simultaneously to obtain the estimates [CS1 Summary, Q4, 423].
* <strong>Least Squares Estimates:</strong>
* <strong>Slope (<span class="math inline">\(\hat{\beta}\)</span>):</strong> <span class="math inline">\(\hat{\beta} = s_{xy} / s_{xx}\)</span> [CS1 Summary, Q5, 424].
* <strong>Intercept (<span class="math inline">\(\hat{\alpha}\)</span>):</strong> <span class="math inline">\(\hat{\alpha} = \bar{y} - \hat{\beta}\bar{x}\)</span> [CS1 Summary, Q5, 424].
* <strong>Estimated Error Variance (<span class="math inline">\(\hat{\sigma}^2\)</span>):</strong> <span class="math inline">\(\hat{\sigma}^2 = \frac{1}{n-2} \left(s_{yy} - \frac{s_{xy}^2}{s_{xx}}\right)\)</span> [CS1 Summary, Q5, 424].
* <em>Note:</em> The fitted regression line <span class="math inline">\(\hat{y} = \hat{\alpha} + \hat{\beta}x\)</span> always passes through the point <span class="math inline">\((\bar{x}, \bar{y})\)</span> [CS1 Summary, Q5b, 426].
* The terms <span class="math inline">\(s_{xx}\)</span>, <span class="math inline">\(s_{yy}\)</span>, <span class="math inline">\(s_{xy}\)</span> are sum of squares and products, found on page 24 of the Tables and in CS1 Summary [CS1 Summary, Q2, 420-421].</p>
</div>
<div id="learning-objective-4-use-r-to-fit-a-simple-linear-regression-model-to-a-data-set-and-interpret-the-output." class="section level4 hasAnchor" number="13.0.0.4">
<h4><span class="header-section-number">13.0.0.4</span> <strong>Learning Objective 4: Use R to fit a simple linear regression model to a data set and interpret the output.</strong><a href="linear-regression.html#learning-objective-4-use-r-to-fit-a-simple-linear-regression-model-to-a-data-set-and-interpret-the-output." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Fitting a Model in R:</strong>
<ul>
<li>Use the <code>lm()</code> function: <code>&lt;name_of_model&gt; &lt;- lm(&lt;response_variable&gt; ~ &lt;explanatory_variable&gt;)</code> [Copy of CS1B Summary 4 - Regression 2020.pdf, 539].</li>
<li>To display coefficients: <code>&lt;name_of_model&gt;</code> [Copy of CS1B Summary 4 - Regression 2020.pdf, 539].</li>
<li>For comprehensive output (estimates, standard errors, t-values, p-values): <code>summary(&lt;name_of_model&gt;)</code> [Copy of CS1B Summary 4 - Regression 2020.pdf, 540].</li>
</ul></li>
<li><strong>Perform Statistical Inference on the Slope Parameter (<span class="math inline">\(\beta\)</span>):</strong>
<ul>
<li><strong>Test Statistic:</strong> Under the full normal model, <span class="math inline">\(\frac{\hat{\beta} - \beta}{\hat{\sigma}/\sqrt{s_{xx}}} \sim t_{n-2}\)</span> [CS1 Summary, Q8, 431].</li>
<li><strong>Hypotheses for testing <span class="math inline">\(\beta = 0\)</span> (no linear relationship):</strong>
<ul>
<li><span class="math inline">\(H_0: \beta = 0\)</span></li>
<li><span class="math inline">\(H_1: \beta \neq 0\)</span> (or one-sided alternatives) [CS1 Summary, Q12, 440].</li>
</ul></li>
<li><strong>Interpretation:</strong> The <code>summary()</code> output provides the t-value and p-value for testing if <span class="math inline">\(\beta\)</span> is significantly different from zero. A low p-value (e.g., &lt; 0.05) indicates sufficient evidence to reject <span class="math inline">\(H_0\)</span>, suggesting a significant linear relationship [CS1 Summary, Q8b, 434].</li>
<li><strong>Confidence Intervals:</strong> Use <code>confint(&lt;name_of_model&gt;, level=0.95)</code> to get CIs for slope and intercept [Copy of CS1B Summary 4 - Regression 2020.pdf, 541].</li>
</ul></li>
<li><strong>Describe the Use of Measures of Goodness of Fit of a Linear Regression Model:</strong>
<ul>
<li><strong>Coefficient of Determination (<span class="math inline">\(R^2\)</span>):</strong>
<ul>
<li>Defined as <span class="math inline">\(R^2 = \frac{SS_{REG}}{SS_{TOT}}\)</span> [CS1 Summary, Q7, 429].</li>
<li>Measures the proportion of the total variation in the response variable (Y) that is explained by the regression model [CS1 Summary, Q7, 429].</li>
<li>Ranges from 0 to 1, often quoted as a percentage [CS1 Summary, Q7, 429].</li>
<li>Higher <span class="math inline">\(R^2\)</span> indicates a better fit [CS1 Summary, Q7a, 430].</li>
<li>It is equal to the square of Pearson’s sample correlation coefficient, <span class="math inline">\(R^2 = r^2\)</span> [CS1 Summary, Q7, 429].</li>
</ul></li>
<li><strong>ANOVA (Analysis of Variance) Table:</strong>
<ul>
<li>Partitions the total variation (<span class="math inline">\(SS_{TOT}\)</span>) into variation explained by the regression (<span class="math inline">\(SS_{REG}\)</span>) and unexplained residual variation (<span class="math inline">\(SS_{RES}\)</span>) [CS1 Summary, Q6, 426]. <span class="math inline">\(SS_{TOT} = SS_{REG} + SS_{RES}\)</span> [CS1 Summary, Q6, 426].</li>
<li>Used to perform an F-test for the overall significance of the regression model (i.e., whether <span class="math inline">\(\beta=0\)</span>) [CS1 Summary, Q12, 440]. A large F-statistic and small p-value lead to rejection of <span class="math inline">\(H_0\)</span> [CS1 Summary, Q12, 442].</li>
<li><code>anova(&lt;name_of_model&gt;)</code> in R provides the ANOVA table [Copy of CS1B Summary 4 - Regression 2020.pdf, 540].</li>
</ul></li>
</ul></li>
<li><strong>Use a Fitted Linear Relationship to Predict a Mean Response or an Individual Response with Confidence Limits:</strong>
<ul>
<li><strong>Mean Response (<span class="math inline">\(\hat{\mu}_0\)</span>):</strong> An estimate of the average Y value for a given X value (<span class="math inline">\(X_0\)</span>) [CS1 Summary, Q19, 451].
<ul>
<li>Formula: <span class="math inline">\(\hat{\mu}_0 = \hat{\alpha} + \hat{\beta}X_0\)</span> [CS1 Summary, Q19, 451].</li>
<li>Confidence interval for the mean response: Accounts for uncertainty in estimating <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> [CS1 Summary, Q10, 437].</li>
</ul></li>
<li><strong>Individual Response (<span class="math inline">\(\hat{y}_0\)</span>):</strong> A prediction for a single future Y observation at a given X value (<span class="math inline">\(X_0\)</span>) [CS1 Summary, Q19, 452].
<ul>
<li>Formula: <span class="math inline">\(\hat{y}_0 = \hat{\alpha} + \hat{\beta}X_0\)</span> [CS1 Summary, Q19, 452].</li>
<li>Prediction interval for an individual response: Accounts for both estimation uncertainty AND the inherent variability of individual observations [CS1 Summary, Q10, 437]. Thus, prediction intervals are always wider than confidence intervals for the mean [CS1-AS, Q26 (iii)(b), 104].</li>
</ul></li>
<li><strong>In R:</strong> <code>predict(&lt;name_of_model&gt;, &lt;new_data_frame&gt;, interval="confidence", level=0.9)</code> for mean response CI, and <code>interval="predict"</code> for individual response PI [Copy of CS1B Summary 4 - Regression 2020.pdf, 541-542].</li>
</ul></li>
<li><strong>Use Residuals to Check the Suitability and Validity of a Linear Regression Model:</strong>
<ul>
<li><strong>Residuals (<span class="math inline">\(\hat{\epsilon}_i\)</span> or <span class="math inline">\(e_i\)</span>):</strong> The difference between the observed value and the fitted value: <span class="math inline">\(\hat{e}_i = Y_i - \hat{Y}_i\)</span> [CS1 Summary, Q13, 442].</li>
<li><strong>Checks:</strong> Residuals should be small, patternless, and normally distributed [CS1 Summary, Q13, 442].
<ul>
<li><strong>Plot residuals vs. fitted values (or explanatory variable):</strong> <code>plot(&lt;name_of_model&gt;, 1)</code> in R [Copy of CS1B Summary 4 - Regression 2020.pdf, 542]. Look for:
<ul>
<li><strong>Patternlessness:</strong> Indicates independence of errors [CS1 Summary, Q13c, 445].</li>
<li><strong>Constant Variance (Homoscedasticity):</strong> The spread of residuals should be consistent across the range of fitted values [CS1 Summary, Q13c, 445].</li>
</ul></li>
<li><strong>Normal Q-Q Plot of residuals:</strong> <code>plot(&lt;name_of_model&gt;, 2)</code> in R [Copy of CS1B Summary 4 - Regression 2020.pdf, 542].
<ul>
<li>Points should lie approximately along a straight diagonal line, indicating normality of errors [CS1 Summary, Q13b, 444]. Deviations suggest non-normality.</li>
</ul></li>
<li>Summary of residuals: <code>summary(&lt;name_of_model&gt;)</code> provides min, max, median, quartiles of residuals [Copy of CS1B Summary 4 - Regression 2020.pdf, 546].</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="learning-objective-5-state-the-multiple-linear-regression-model-with-several-explanatory-variables." class="section level4 hasAnchor" number="13.0.0.5">
<h4><span class="header-section-number">13.0.0.5</span> <strong>Learning Objective 5: State the multiple linear regression model (with several explanatory variables).</strong><a href="linear-regression.html#learning-objective-5-state-the-multiple-linear-regression-model-with-several-explanatory-variables." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The multiple linear regression model extends the simple linear model to include multiple explanatory variables [CS1 Summary, Q14, 445].
* <strong>Model Equation:</strong> <span class="math inline">\(Y_i = \alpha + \beta_1 X_{i1} + \beta_2 X_{i2} + \dots + \beta_k X_{ik} + \epsilon_i\)</span> [CS1 Summary, Q14, 445].
* <span class="math inline">\(Y_i\)</span>: Response variable for the <span class="math inline">\(i\)</span>-th observation [CS1 Summary, Q14, 445].
* <span class="math inline">\(X_{i1}, \dots, X_{ik}\)</span>: <span class="math inline">\(k\)</span> explanatory variables for the <span class="math inline">\(i\)</span>-th observation [CS1 Summary, Q14, 445].
* <span class="math inline">\(\alpha\)</span>: Intercept [CS1 Summary, Q14, 445].
* <span class="math inline">\(\beta_1, \dots, \beta_k\)</span>: Slope parameters for each explanatory variable [CS1 Summary, Q14, 445].
* <span class="math inline">\(\epsilon_i\)</span>: Error term [CS1 Summary, Q14, 446].
* <strong>Full Normal Model Assumptions:</strong> Similar to simple linear regression, the errors <span class="math inline">\(\epsilon_i\)</span> are independent and normally distributed: <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span> [CS1 Summary, Q14, 446].</p>
</div>
<div id="learning-objective-6-use-r-to-fit-a-multiple-linear-regression-model-to-a-data-set-and-interpret-the-output." class="section level4 hasAnchor" number="13.0.0.6">
<h4><span class="header-section-number">13.0.0.6</span> <strong>Learning Objective 6: Use R to fit a multiple linear regression model to a data set and interpret the output.</strong><a href="linear-regression.html#learning-objective-6-use-r-to-fit-a-multiple-linear-regression-model-to-a-data-set-and-interpret-the-output." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Fitting a Model in R:</strong>
<ul>
<li>Use the <code>lm()</code> function, listing all explanatory variables separated by <code>+</code>: <code>&lt;name_of_model&gt; &lt;- lm(&lt;response_variable&gt; ~ &lt;X1&gt; + &lt;X2&gt; + ...)</code> [Copy of CS1B Summary 4 - Regression 2020.pdf, 543].</li>
<li>For interactions, use <code>X1:X2</code> or <code>X1*X2</code> (which includes main effects and interaction) [Copy of CS1B Summary 4 - Regression 2020.pdf, 544].</li>
<li>Output is accessed via <code>summary(&lt;name_of_model&gt;)</code> [Copy of CS1B Summary 4 - Regression 2020.pdf, 544].</li>
</ul></li>
<li><strong>Interpreting Output:</strong>
<ul>
<li><strong>Coefficients Table:</strong> Provides estimates, standard errors, t-values, and p-values for <span class="math inline">\(\alpha\)</span> and each <span class="math inline">\(\beta_j\)</span> [CS1 Summary, Q18a, 450; Copy of CS1B Summary 4 - Regression 2020.pdf, 544].
<ul>
<li>A low p-value for a <span class="math inline">\(\beta_j\)</span> indicates that <span class="math inline">\(X_j\)</span> is a significant predictor <em>after accounting for other variables in the model</em> [CS1 Summary, Q18, 449].</li>
</ul></li>
<li><strong>R-squared (<span class="math inline">\(R^2\)</span>) and Adjusted R-squared (Adjusted <span class="math inline">\(R^2\)</span>):</strong>
<ul>
<li><span class="math inline">\(R^2\)</span> is the proportion of variability explained by the model [Copy of CS1B Summary 4 - Regression 2020.pdf, 545].</li>
<li>Adjusted <span class="math inline">\(R^2\)</span> adjusts <span class="math inline">\(R^2\)</span> for the number of predictors, penalising models with more parameters [CS1 Summary, Q17, 448]. It is generally preferred for model comparison [CS1 Summary, Q17, 448].</li>
</ul></li>
<li><strong>F-statistic and overall p-value:</strong>
<ul>
<li>Tests the global null hypothesis that <em>all</em> slope parameters are zero (<span class="math inline">\(H_0: \beta_1 = \beta_2 = \dots = \beta_k = 0\)</span>) [CS1 Summary, Q20, 453].</li>
<li>A low p-value indicates that at least one explanatory variable is a significant predictor [CS1 Summary, Q20, 455].</li>
</ul></li>
<li>Confidence intervals for parameters: <code>confint(&lt;name_of_model&gt;, level=0.95)</code> [Copy of CS1B Summary 4 - Regression 2020.pdf, 545].</li>
</ul></li>
</ul>
</div>
<div id="learning-objective-7-use-measures-of-model-fit-to-select-an-appropriate-set-of-explanatory-variables." class="section level4 hasAnchor" number="13.0.0.7">
<h4><span class="header-section-number">13.0.0.7</span> <strong>Learning Objective 7: Use measures of model fit to select an appropriate set of explanatory variables.</strong><a href="linear-regression.html#learning-objective-7-use-measures-of-model-fit-to-select-an-appropriate-set-of-explanatory-variables." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Selecting the optimal set of explanatory variables is crucial for building parsimonious yet accurate models.
* <strong>Adjusted R-squared (<span class="math inline">\(R^2_{adj}\)</span>):</strong>
* As noted above, it accounts for the number of predictors [CS1 Summary, Q17, 448].
* A higher <span class="math inline">\(R^2_{adj}\)</span> generally indicates a better model [CS1 Summary, Q17, 448].
* <strong>Akaike Information Criterion (AIC):</strong> A measure that balances model fit and complexity; lower AIC indicates a better model [CS1 Summary, Q22, 482]. (Note: AIC is not explicitly detailed in the provided sources for linear regression, but it is mentioned for GLMs and variable selection generally. It is a common measure in model selection.)
* <strong>Statistical Significance of Parameters:</strong> Include only covariates where the hypothesis that <span class="math inline">\(\beta_j=0\)</span> can be rejected (i.e., they are statistically significant) [CS1 Summary, Q18, 449].
* <strong>Stepwise Selection Methods:</strong>
* <strong>Forward Selection:</strong> Start with a null model (intercept only) and iteratively add the covariate that most significantly improves the model (e.g., reduces AIC the most or causes a significant decrease in deviance) until no further significant improvement is found [CS1 Summary, Q22, 482; Copy of CS1B Summary 4 - Regression 2020.pdf, 546].
* <strong>Backward Elimination:</strong> Start with a full model (all available covariates) and iteratively remove the least significant covariate (e.g., highest p-value for <span class="math inline">\(\beta_j\)</span> coefficient, or causes AIC to reach a minimum) until all remaining covariates are statistically significant [CS1 Summary, Q23, 483].</p>
<p>These tools and techniques are vital for developing robust predictive models in actuarial science. Keep practicing!</p>
</div>
</div>
<div id="practice-linear-regression" class="section level2 unnumbered hasAnchor">
<h2><code>R</code> Practice<a href="linear-regression.html#practice-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="goodness-of-fit.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="generalised-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["twitter", "linkedin"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/priyam0k/CS1/edit/main/linear-regression.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
