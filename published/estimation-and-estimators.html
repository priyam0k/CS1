<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Estimation and estimators | Actuarial Statistics (Priyam’s Fork)</title>
  <meta name="description" content="A modified version of the book on actuarial statistics, with additional notes and examples." />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Estimation and estimators | Actuarial Statistics (Priyam’s Fork)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A modified version of the book on actuarial statistics, with additional notes and examples." />
  <meta name="github-repo" content="priyam0k/CS1" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Estimation and estimators | Actuarial Statistics (Priyam’s Fork)" />
  
  <meta name="twitter:description" content="A modified version of the book on actuarial statistics, with additional notes and examples." />
  

<meta name="author" content="Priyam" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="random-sampling.html"/>
<link rel="next" href="confidence-intervals.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Actuarial Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#motivation"><i class="fa fa-check"></i>Motivation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="r-setup.html"><a href="r-setup.html"><i class="fa fa-check"></i><b>1</b> R Setup</a>
<ul>
<li class="chapter" data-level="1.1" data-path="r-setup.html"><a href="r-setup.html#preparing-your-environment-for-r"><i class="fa fa-check"></i><b>1.1</b> Preparing your environment for <code>R</code></a></li>
<li class="chapter" data-level="1.2" data-path="r-setup.html"><a href="r-setup.html#basic-interations-with-r"><i class="fa fa-check"></i><b>1.2</b> Basic interations with <code>R</code></a></li>
<li class="chapter" data-level="1.3" data-path="r-setup.html"><a href="r-setup.html#functions-in-r"><i class="fa fa-check"></i><b>1.3</b> Functions in <code>R</code></a></li>
<li class="chapter" data-level="1.4" data-path="r-setup.html"><a href="r-setup.html#data-structures-in-r"><i class="fa fa-check"></i><b>1.4</b> Data structures in <code>R</code></a>
<ul>
<li class="chapter" data-level="" data-path="r-setup.html"><a href="r-setup.html#matrices"><i class="fa fa-check"></i>Matrices</a></li>
<li class="chapter" data-level="" data-path="r-setup.html"><a href="r-setup.html#dataframes"><i class="fa fa-check"></i>Dataframes</a></li>
<li class="chapter" data-level="" data-path="r-setup.html"><a href="r-setup.html#lists"><i class="fa fa-check"></i>Lists</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="r-setup.html"><a href="r-setup.html#logical-expressions-in-r"><i class="fa fa-check"></i><b>1.5</b> Logical expressions in <code>R</code></a></li>
<li class="chapter" data-level="1.6" data-path="r-setup.html"><a href="r-setup.html#extending-r-with-packages"><i class="fa fa-check"></i><b>1.6</b> Extending <code>R</code> with packages</a></li>
<li class="chapter" data-level="1.7" data-path="r-setup.html"><a href="r-setup.html#importing-data"><i class="fa fa-check"></i><b>1.7</b> Importing data</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>2</b> Discrete Probability Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#objectives-discrete-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#theory-discrete-distributions"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="2.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#in-built-probability-distributions"><i class="fa fa-check"></i><b>2.1</b> In-built probability distributions</a></li>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-probability-distributions-covered"><i class="fa fa-check"></i>Discrete probability distributions covered</a></li>
<li class="chapter" data-level="2.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>2.2</b> Geometric distribution</a></li>
<li class="chapter" data-level="2.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>2.3</b> Binomial distribution</a></li>
<li class="chapter" data-level="2.4" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>2.4</b> Negative binomial distribution</a></li>
<li class="chapter" data-level="2.5" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>2.5</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="2.6" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>2.6</b> Poisson distribution</a></li>
<li class="chapter" data-level="2.7" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#discrete-uniform"><i class="fa fa-check"></i><b>2.7</b> Uniform distribution</a></li>
<li class="chapter" data-level="" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#practice-discrete-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html"><i class="fa fa-check"></i><b>3</b> Continuous Probability Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#objectives-continuous-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#theory-continuous-distributions"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="3.1" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#in-built-probability-distributions-1"><i class="fa fa-check"></i><b>3.1</b> In-built probability distributions</a></li>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#continuous-probability-distributions-covered"><i class="fa fa-check"></i>Continuous probability distributions covered</a></li>
<li class="chapter" data-level="3.2" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>3.2</b> Normal distribution</a></li>
<li class="chapter" data-level="3.3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#lognormal-distribution"><i class="fa fa-check"></i><b>3.3</b> Lognormal distribution</a></li>
<li class="chapter" data-level="3.4" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>3.4</b> Exponential distribution</a></li>
<li class="chapter" data-level="3.5" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>3.5</b> Gamma distribution</a></li>
<li class="chapter" data-level="3.6" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#chi2-distribution"><i class="fa fa-check"></i><b>3.6</b> <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="3.7" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>3.7</b> Student’s <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="3.8" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#f-distribution"><i class="fa fa-check"></i><b>3.8</b> <span class="math inline">\(F\)</span> distribution</a></li>
<li class="chapter" data-level="3.9" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>3.9</b> Beta distribution</a></li>
<li class="chapter" data-level="3.10" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#continuous-uniform"><i class="fa fa-check"></i><b>3.10</b> Uniform distribution</a></li>
<li class="chapter" data-level="3.11" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#inverse-transform-method"><i class="fa fa-check"></i><b>3.11</b> Inverse transform method</a></li>
<li class="chapter" data-level="" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#practice-continuous-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html"><i class="fa fa-check"></i><b>4</b> Joint and Conditional Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#objectives-joint-distributions"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#theory-joint-distributions"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#definition-and-representation"><i class="fa fa-check"></i><b>4.0.1</b> 1. Definition and Representation</a></li>
<li class="chapter" data-level="4.0.2" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#marginal-and-conditional-distributions"><i class="fa fa-check"></i><b>4.0.2</b> 2. Marginal and Conditional Distributions</a></li>
<li class="chapter" data-level="4.0.3" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#independence-of-random-variables"><i class="fa fa-check"></i><b>4.0.3</b> 3. Independence of Random Variables</a></li>
<li class="chapter" data-level="4.0.4" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#expectation-covariance-and-correlation"><i class="fa fa-check"></i><b>4.0.4</b> 4. Expectation, Covariance, and Correlation</a></li>
<li class="chapter" data-level="4.0.5" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#linear-combinations-and-sums-of-random-variables"><i class="fa fa-check"></i><b>4.0.5</b> 5. Linear Combinations and Sums of Random Variables</a></li>
<li class="chapter" data-level="4.0.6" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#practical-applications"><i class="fa fa-check"></i><b>4.0.6</b> 6. Practical Applications</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="joint-and-conditional-distributions.html"><a href="joint-and-conditional-distributions.html#practice-joint-distributions"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>5</b> Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#objectives-clt"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#theory-clt"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#practice-clt"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-analysis.html"><a href="data-analysis.html"><i class="fa fa-check"></i><b>6</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="data-analysis.html"><a href="data-analysis.html#objectives-data-analysis"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="data-analysis.html"><a href="data-analysis.html#theory-data-analysis"><i class="fa fa-check"></i>Theory</a>
<ul>
<li class="chapter" data-level="6.0.1" data-path="data-analysis.html"><a href="data-analysis.html#definition-and-purpose"><i class="fa fa-check"></i><b>6.0.1</b> 1. Definition and Purpose</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-analysis.html"><a href="data-analysis.html#practice-data-analysis"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>7</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#objectives-exploratory-data-analysis"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#theory-exploratory-data-analysis"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#practice-exploratory-data-analysis"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="random-sampling.html"><a href="random-sampling.html"><i class="fa fa-check"></i><b>8</b> Random Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="random-sampling.html"><a href="random-sampling.html#objectives-random-sampling"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="random-sampling.html"><a href="random-sampling.html#theory-random-sampling"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="random-sampling.html"><a href="random-sampling.html#practice-random-sampling"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html"><i class="fa fa-check"></i><b>9</b> Estimation and estimators</a>
<ul>
<li class="chapter" data-level="" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html#objectives-estimators"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html#theory-estimators"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="estimation-and-estimators.html"><a href="estimation-and-estimators.html#practice-estimators"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#objectives-confidence-intervals"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#theory-confidence-intervals"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#practice-confidence-intervals"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#objectives-hypothesis-testing"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#theory-hypothesis-testing"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-hypothesis-testing"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html"><i class="fa fa-check"></i><b>12</b> Goodness of Fit</a>
<ul>
<li class="chapter" data-level="" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#objectives-goodness-of-fit"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#theory-goodness-of-fit"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="goodness-of-fit.html"><a href="goodness-of-fit.html#practice-goodness-of-fit"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>13</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#objectives-linear-regression"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#theory-linear-regression"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="linear-regression.html#practice-linear-regression"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html"><i class="fa fa-check"></i><b>14</b> Generalised Linear Models</a>
<ul>
<li class="chapter" data-level="" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#objectives-glm"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#theory-glm"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="generalised-linear-models.html"><a href="generalised-linear-models.html#practice-glm"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>15</b> Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#objectives-bayesian-stats"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#theory-bayesian-stats"><i class="fa fa-check"></i>Theory</a></li>
<li class="chapter" data-level="" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#practice-bayesian-stats"><i class="fa fa-check"></i><code>R</code> Practice</a></li>
</ul></li>
<li class="divider"></li>
<li>Adapted by <a href="https://github.com/priyam0k">Priyam</a> from the original by <a href="https://github.com/agarbiak" target="blank">Alex Garbiak</a>.</li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Actuarial Statistics (Priyam’s Fork)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimation-and-estimators" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Estimation and estimators<a href="estimation-and-estimators.html#estimation-and-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objectives-estimators" class="section level2 unnumbered hasAnchor">
<h2>Learning Objectives<a href="estimation-and-estimators.html#objectives-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Describe and apply the method of moments for constructing estimators of population parameters.</li>
<li>Describe and apply the method of maximum likelihood for constructing estimators of population parameters.</li>
<li>Define the terms: efficiency, bias, consistency and mean squared error.</li>
<li>Define and apply the property of unbiasedness of an estimator.</li>
<li>Define the mean square error of an estimator, and use it to compare estimators.</li>
<li>Describe and apply the asymptotic distribution of maximum likelihood estimators.</li>
<li>Use the bootstrap method to estimate properties of an estimator.</li>
</ol>
</div>
<div id="theory-estimators" class="section level2 unnumbered hasAnchor">
<h2>Theory<a href="estimation-and-estimators.html#theory-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Point Estimation (Estimation and Estimators)</p>
<p>This chapter focuses on different methods for estimating unknown population parameters from sample data and evaluating the quality of those estimators.</p>
<div id="method-of-moments-mom-for-constructing-estimators" class="section level4 hasAnchor" number="9.0.0.1">
<h4><span class="header-section-number">9.0.0.1</span> 1. Method of Moments (MOM) for Constructing Estimators<a href="estimation-and-estimators.html#method-of-moments-mom-for-constructing-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Definition:</strong> The Method of Moments involves equating sample moments to their corresponding population (or theoretical) moments.</li>
<li><strong>Application:</strong>
<ul>
<li><strong>For 1 unknown parameter (e.g., Poi(μ), Exp(λ)):</strong> Equate the sample mean (x̄) to the population mean (E[X]).
<ul>
<li><em>Example:</em> For an Exp(λ) distribution, λ̂ = 1/x̄.</li>
</ul></li>
<li><strong>For 2 unknown parameters (e.g., NBin(k,p), Gamma(α,λ), N(μ,σ²)):</strong> Equate the sample mean and sample variance to their population counterparts. Alternatively, equate the first two moments about zero.</li>
</ul></li>
<li><strong>Characteristics:</strong>
<ul>
<li>May be simple to calculate.</li>
<li>May sometimes produce inadmissible values (estimates that are not possible within the parameter space).</li>
</ul></li>
</ul>
</div>
<div id="method-of-maximum-likelihood-mle-for-constructing-estimators" class="section level4 hasAnchor" number="9.0.0.2">
<h4><span class="header-section-number">9.0.0.2</span> 2. Method of Maximum Likelihood (MLE) for Constructing Estimators<a href="estimation-and-estimators.html#method-of-maximum-likelihood-mle-for-constructing-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Definition:</strong> The Maximum Likelihood Estimate (MLE) is the value of the parameter that maximizes the likelihood of observing the given sample data. In essence, it finds the parameter value that makes the observed data “most probable”.</li>
<li><strong>Application Stages (Single-parameter case):</strong>
<ol style="list-style-type: decimal">
<li><strong>Write down the likelihood function (L):</strong> This is the probability (for discrete data) or probability density (for continuous data) of obtaining the observed sample, viewed as a function of the parameter(s).</li>
<li><strong>Obtain the log-likelihood (ln L):</strong> Taking the natural logarithm simplifies differentiation.</li>
<li><strong>Differentiate and set to zero:</strong> Differentiate ln L with respect to the parameter(s) and set the derivative(s) equal to zero. Solving these equations yields the MLE(s).</li>
<li><strong>(Optional check):</strong> Differentiate again to ensure the second derivative is negative, confirming a maximum.</li>
</ol></li>
<li><strong>Examples:</strong> For a Poisson(μ) distribution, the MLE of μ is the sample mean (x̄).</li>
<li><strong>Tricky Situations:</strong>
<ul>
<li><strong>Incomplete data:</strong> For censored or truncated data, the method requires careful formulation of the likelihood function.</li>
<li><strong>Domain parameters:</strong> When the parameter’s possible values are bounded (e.g., uniform distribution’s upper bound), the MLE might be found at the boundary of the parameter space, often requiring visual inspection or numerical methods rather than differentiation.</li>
</ul></li>
</ul>
</div>
<div id="definitions-efficiency-bias-consistency-mean-squared-error" class="section level4 hasAnchor" number="9.0.0.3">
<h4><span class="header-section-number">9.0.0.3</span> 3. Definitions: Efficiency, Bias, Consistency, Mean Squared Error<a href="estimation-and-estimators.html#definitions-efficiency-bias-consistency-mean-squared-error" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Bias:</strong> For an estimator θ̂ of a parameter θ, the bias is defined as <code>Bias(θ̂) = E[θ̂] - θ</code>.</li>
<li><strong>Mean Squared Error (MSE):</strong> For an estimator θ̂ of a parameter θ, the MSE is defined as <code>MSE(θ̂) = E[(θ̂ - θ)²]</code>.</li>
<li><strong>Efficiency:</strong> An estimator θ̂₁ is considered more efficient than another estimator θ̂₂ if <code>MSE(θ̂₁) &lt; MSE(θ̂₂)</code>. A lower MSE means the estimator is, on average, closer to the true parameter value.</li>
<li><strong>Consistency:</strong> An estimator θ̂ is consistent if its <code>MSE(θ̂) → 0</code> as the sample size <code>n → ∞</code>. This implies that with a sufficiently large sample, the estimator will converge to the true parameter value.</li>
</ul>
</div>
<div id="property-of-unbiasedness-of-an-estimator" class="section level4 hasAnchor" number="9.0.0.4">
<h4><span class="header-section-number">9.0.0.4</span> 4. Property of Unbiasedness of an Estimator<a href="estimation-and-estimators.html#property-of-unbiasedness-of-an-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Definition:</strong> An estimator θ̂ is unbiased for θ if its bias is zero, i.e., <code>E[θ̂] = θ</code>. This means, on average, the estimator will hit the true parameter value.</li>
<li><strong>Application:</strong>
<ul>
<li>The sample mean (x̄) is an unbiased estimator of the population mean (μ).</li>
<li>The sample variance (S²) calculated with <code>1/(n-1)</code> in the denominator is an unbiased estimator of the population variance (σ²).</li>
</ul></li>
</ul>
</div>
<div id="mean-squared-error-mse-and-comparison-of-estimators" class="section level4 hasAnchor" number="9.0.0.5">
<h4><span class="header-section-number">9.0.0.5</span> 5. Mean Squared Error (MSE) and Comparison of Estimators<a href="estimation-and-estimators.html#mean-squared-error-mse-and-comparison-of-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Formula:</strong> The MSE can be decomposed into the variance of the estimator and the square of its bias: <code>MSE(θ̂) = Var(θ̂) + (Bias(θ̂))²</code>. This formula is key for evaluating an estimator’s overall quality.</li>
<li><strong>Comparison:</strong> To compare estimators, calculate their MSEs. The estimator with the smaller MSE is preferred because it represents a better balance between bias and variance, indicating greater accuracy around the true parameter. Sometimes, a slightly biased estimator might be chosen over an unbiased one if its MSE is significantly lower.</li>
</ul>
</div>
<div id="asymptotic-distribution-of-maximum-likelihood-estimators" class="section level4 hasAnchor" number="9.0.0.6">
<h4><span class="header-section-number">9.0.0.6</span> 6. Asymptotic Distribution of Maximum Likelihood Estimators<a href="estimation-and-estimators.html#asymptotic-distribution-of-maximum-likelihood-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Asymptotic Property:</strong> For large sample sizes, the Maximum Likelihood Estimator (MLE), θ̂, is asymptotically normally distributed: <code>θ̂ ~ N(θ, CRLB)</code>.</li>
<li><strong>Approximate Standard Error:</strong> For a sufficiently large sample size, the standard error of the MLE is approximately equal to the square root of the Cramer-Rao Lower Bound (CRLB).</li>
<li><strong>Cramer-Rao Lower Bound (CRLB):</strong> This is the theoretical minimum variance an unbiased estimator can achieve. It’s given by <code>CRLB = 1 / E[-(d²lnL/dθ²)]</code>. For instance, for the Poisson(μ) parameter, the CRLB is <code>μ/n</code>. If an unbiased estimator’s variance equals the CRLB, it is considered a minimum variance unbiased estimator (MVUE).</li>
</ul>
</div>
<div id="bootstrap-method-to-estimate-properties-of-an-estimator" class="section level4 hasAnchor" number="9.0.0.7">
<h4><span class="header-section-number">9.0.0.7</span> 7. Bootstrap Method to Estimate Properties of an Estimator<a href="estimation-and-estimators.html#bootstrap-method-to-estimate-properties-of-an-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Purpose:</strong> The bootstrap method is a resampling technique used to estimate the sampling distribution of a statistic, which in turn helps in constructing confidence intervals or estimating other properties of an estimator when analytical methods are difficult or impossible.</li>
<li><strong>Method Outline:</strong>
<ol style="list-style-type: decimal">
<li><strong>Generate Resamples:</strong> Create multiple “bootstrap samples” by drawing observations with replacement from the original observed sample (non-parametric bootstrap). Alternatively, if a distribution is assumed, simulate samples from the fitted distribution (parametric bootstrap).</li>
<li><strong>Calculate Statistic:</strong> For each of these bootstrap samples, calculate the statistic of interest (e.g., the estimator of the parameter).</li>
<li><strong>Empirical Distribution:</strong> The collection of calculated statistics from all bootstrap samples forms an empirical sampling distribution. This distribution can then be used for statistical inference, such as deriving confidence intervals by finding appropriate quantiles of the bootstrap distribution.</li>
</ol></li>
</ul>
</div>
</div>
<div id="practice-estimators" class="section level2 unnumbered hasAnchor">
<h2><code>R</code> Practice<a href="estimation-and-estimators.html#practice-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-sampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": true,
    "linkedin": true,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["twitter", "linkedin"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/priyam0k/CS1/edit/main/estimators.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
