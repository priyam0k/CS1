---
title: "Actuarial Statistics (Priyam's Fork)"
author: "Priyam"
date: "`r format(Sys.time(), '%d %B, %Y')`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: priyam0k/CS1
description: "A modified version of the book on actuarial statistics, with additional notes and examples."
favicon: img/favicon.ico
---
---
title: "Actuarial Statistics (Priyam's Fork)"
author: "Priyam"
date: "`r format(Sys.time(), '%d %B, %Y')`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: priyam0k/CS1
description: "A modified version of the book on actuarial statistics, with additional notes and examples."
favicon: img/favicon.ico
---

# Introduction {-}

This book is a modified version of the original work by **Alex Garbiak**. As an adapted version, there may be changes, bugs, typos, or errors. Please report any issues you find [here](https://github.com/priyam0k/CS1/issues).

## Motivation {-}

The purpose of this book is to build upon the original work for studying [Actuarial Statistics (CS1)](https://www.actuaries.org.uk/studying/curriculum/actuarial-statistics) from the Institute and Faculty of Actuaries by providing updated `R` code examples across the following topic areas:

1.  Random variables and distributions
2.  Data analysis
3.  Statistical inference
4.  Regression theory and applications
5.  Bayesian statistics

<!--chapter:end:index.Rmd-->


# R Setup

Placeholder


## Preparing your environment for `R`
## Basic interations with `R`
## Functions in `R`
## Data structures in `R`
### Matrices {-}
### Dataframes {-}
### Lists {-}
## Logical expressions in `R`
## Extending `R` with packages
## Importing data

<!--chapter:end:setup.Rmd-->


# Discrete Probability Distributions

Placeholder


## Learning Objectives {-#objectives-discrete-distributions}
## Theory {-#theory-discrete-distributions}
## In-built probability distributions
## Discrete probability distributions covered {-}
## Geometric distribution
## Binomial distribution
## Negative binomial distribution
## Hypergeometric distribution
## Poisson distribution
## Uniform distribution {#discrete-uniform}
## `R` Practice {-#practice-discrete-distributions}

<!--chapter:end:discrete-distributions.Rmd-->


# Continuous Probability Distributions

Placeholder


## Learning Objectives {-#objectives-continuous-distributions}
## Theory {-#theory-continuous-distributions}
## In-built probability distributions
## Continuous probability distributions covered {-}
## Normal distribution
## Lognormal distribution
## Exponential distribution
## Gamma distribution
## $\chi^2$ distribution
## Student's $t$ distribution
## $F$ distribution
## Beta distribution
## Uniform distribution {#continuous-uniform}
## Inverse transform method
## `R` Practice {-#practice-continuous-distributions}

<!--chapter:end:continuous-distributions.Rmd-->


# Joint and Conditional Distributions

Placeholder


## Learning Objectives {-#objectives-joint-distributions}
## Theory {-#theory-joint-distributions}
### 1. Definition and Representation
### 2. Marginal and Conditional Distributions
### 3. Independence of Random Variables
### 4. Expectation, Covariance, and Correlation
### 5. Linear Combinations and Sums of Random Variables
### 6. Practical Applications
## `R` Practice {-#practice-joint-distributions}

<!--chapter:end:joint-distributions.Rmd-->


# Central Limit Theorem

Placeholder


## Learning Objectives {-#objectives-clt}
## Theory {-#theory-clt}
#### 1. Statement of the Central Limit Theorem (CLT) for a sequence of independent, identically distributed random variables
#### 2. Generating Simulated Samples and Comparing with the Normal Distribution
## `R` Practice {-#practice-clt}

<!--chapter:end:clt.Rmd-->


# Data Analysis

Placeholder


## Learning Objectives {-#objectives-data-analysis}
## Theory {-#theory-data-analysis}
### 1. Definition and Purpose
#### 2. Key Forms of Data Analysis
#### 3. The Data Analysis Process
#### 4. Types of Data
#### 5. Summarising Data
#### 6. Comparing Data Sets
#### 7. Data Management Principles
#### 8. Reproducibility
## `R` Practice {-#practice-data-analysis}

<!--chapter:end:data-analysis.Rmd-->

# Exploratory Data Analysis

## Learning Objectives {-#objectives-exploratory-data-analysis}

1. Describe the purpose of exploratory data analysis.
2. Use appropriate tools to calculate suitable summary statistics and undertake exploratory data visualizations.
3. Define and calculate Pearson’s, Spearman’s and Kendall’s measures of correlation for bivariate data, explain their interpretation and perform statistical inference as appropriate.
4. Use Principal Components Analysis to reduce the dimensionality of a complex data set.

## Theory {-#theory-exploratory-data-analysis}

#### 1. Purpose of Exploratory Data Analysis
*   EDA is the process of analysing data to gain initial insights into its nature, patterns, and relationships between variables *before* formal statistical techniques are applied.
*   Its primary aim is to understand "what is going on" with the data, summarising it into a more easily understood format.

#### 2. Tools for Summary Statistics and Data Visualisation
EDA employs various tools depending on the number of variables:

*   **For Univariate Data (Single Variable)**:
    *   **Summary Statistics**:
        *   Measures of central tendency: Mean, Median, Mode.
        *   Measures of dispersion: Standard Deviation, Interquartile Range (IQR), Range, Skewness.
    *   **Graphical Displays**:
        *   Line plots.
        *   Bar charts (for discrete or categorical data).
        *   Histograms (for continuous data, where bar *area* represents frequency).
        *   Stem and leaf diagrams (displaying distribution and aiding quartile identification).
        *   Cumulative frequency graphs (for estimating percentiles).
        *   Boxplots (Box and Whisker Plots) (showing lowest/highest values, median, quartiles; useful for comparing datasets).
        *   Quantile-quantile (Q-Q) plots.

*   **For Bivariate or Multivariate Data (Multiple Variables)**:
    *   **Summary Statistics**: Individual variable summary statistics.
    *   **Graphical Displays**:
        *   Scatterplots (to visualise relationships between pairs of variables).

#### 3. Correlation Measures for Bivariate Data
These coefficients quantify the strength and direction of relationships between variables:

*   **Pearson's Correlation Coefficient (r)**:
    *   **Definition**: Measures the strength and direction of a *linear* relationship between two quantitative variables.
    *   **Formula**: `r = s_xy / (s_x * s_y)`.
    *   **Interpretation**: Values range from -1 to +1. Near +1 indicates a strong positive linear relationship, near -1 indicates a strong negative linear relationship, and near 0 indicates no linear correlation.
    *   **Statistical Inference**: A t-distribution based test is available for the hypothesis that the population correlation coefficient (ρ) is zero. Fisher's transformation can be used for testing hypotheses about specific non-zero values of ρ.
    *   **Crucial Caveat**: Correlation does not necessarily imply causation.

*   **Spearman's Rank Correlation Coefficient (r_s)**:
    *   **Definition**: Measures the strength of a *monotonic* (not necessarily linear) relationship between two variables.
    *   **Calculation**: Applied by calculating Pearson's formula on the *ranks* of the data.
    *   **Statistical Inference**: Tests exist for both small samples (using permutations of ranks) and medium to large samples (using an approximate Normal distribution).

*   **Kendall's Rank Correlation Coefficient (τ)**:
    *   **Definition**: Another non-parametric measure of monotonic association, based on the number of concordant and discordant pairs in the data.
    *   **Statistical Inference**: Similar to Spearman's, tests are available for small samples (permutations) and medium to large samples (using an approximate Normal distribution).

#### 4. Principal Components Analysis (PCA)
*   **Purpose**: PCA is a method for reducing the dimensionality of a complex dataset by identifying the key components necessary to model and understand the data.
*   **Mechanism**: It creates uncorrelated linear combinations of the original variables, where these new components (principal components) maximise the variance explained.
*   **Process**:
    1.  Calculate the centred data.
    2.  Obtain eigenvectors of the scaled covariance matrix, which represent the "rotation" of the data.
    3.  Compute the principal components, which are the new uncorrelated variables.
    4.  Evaluate the explanatory power (variance) of each component.
    5.  Reduce the number of components by discarding those that explain less variance.
    6.  Reconstruct the original data using the reduced set of components.
*   **Component Selection Criteria**:
    *   **Cumulative Variance Explained**: Retain components that collectively explain a target percentage (e.g., 90%) of the total variance.
    *   **Scree Test**: Plot a scree diagram and keep components before the graph "levels off".
    *   **Kaiser Criterion**: If data is scaled, keep components whose variance is greater than 1.

## `R` Practice {-#practice-exploratory-data-analysis}

<!--chapter:end:exploratory-data-analysis.Rmd-->


# Random Sampling

Placeholder


## Learning Objectives {-#objectives-random-sampling}
## Theory {-#theory-random-sampling}
#### 1. What is Meant by a Sample, a Population, and Statistical Inference?
#### 2. Defining a Random Sample
#### 3. Understanding a Statistic and its Sampling Distribution
#### 4. Mean and Variance of Sample Mean (X̄) and Sample Variance (S²)
#### 5. Basic Sampling Distributions for Normal Samples
#### 6. The t-statistic for Random Samples from a Normal Distribution
#### 7. F-Distribution for Ratio of Two Sample Variances from Independent Normal Samples
## `R` Practice {-#practice-random-sampling}

<!--chapter:end:random-sampling.Rmd-->

# Estimation and estimators

## Learning Objectives {-#objectives-estimators}

1. Describe and apply the method of moments for constructing estimators of population parameters.
2. Describe and apply the method of maximum likelihood for constructing estimators of population parameters.
3. Define the terms: efficiency, bias, consistency and mean squared error.
4. Define and apply the property of unbiasedness of an estimator.
5. Define the mean square error of an estimator, and use it to compare estimators.
6. Describe and apply the asymptotic distribution of maximum likelihood estimators.
7. Use the bootstrap method to estimate properties of an estimator.

## Theory {-#theory-estimators}

## `R` Practice {-#practice-estimators}

<!--chapter:end:estimators.Rmd-->

# Confidence Intervals

## Learning Objectives {-#objectives-confidence-intervals}

1. Define in general terms a confidence interval for an unknown parameter of a distribution based on a random sample.
2. Derive a confidence interval for an unknown parameter using a given sampling distribution.
3. Calculate confidence intervals for the mean and the variance of a normal distribution.
4. Calculate confidence intervals for a binomial probability and a Poisson mean, including the use of the normal approximation in both cases.
5. Calculate confidence intervals for two-sample situations involving the normal distribution, and the binomial and Poisson distributions using the normal approximation.
6. Calculate confidence intervals for a difference between two means from paired data.
7. Use the bootstrap method to obtain confidence intervals.

## Theory {-#theory-confidence-intervals}

## `R` Practice {-#practice-confidence-intervals}

<!--chapter:end:confidence-intervals.Rmd-->

# Hypothesis Testing

## Learning Objectives {-#objectives-hypothesis-testing}

1. Explain what is meant by the terms null and alternative hypotheses, simple and composite hypotheses, type I and type II errors, test statistic, likelihood ratio, critical region, level of significance, probability-value and power of a test.
2. Apply basic tests for the one-sample and two-sample situations involving the normal, binomial and Poisson distributions, and apply basic tests for paired data.
3. Apply the permutation approach to non-parametric hypothesis tests.

## Theory {-#theory-hypothesis-testing}

## `R` Practice {-#practice-hypothesis-testing}

<!--chapter:end:hypothesis-testing.Rmd-->

# Goodness of Fit

## Learning Objectives {-#objectives-goodness-of-fit}

1. Use a chi-square test to test the hypothesis that a random sample is from a particular distribution, including cases where parameters are unknown.
2. Explain what is meant by a contingency (or two-way) table, and use a chi-square test to test the independence of two classification criteria.

## Theory {-#theory-goodness-of-fit}

## `R` Practice {-#practice-goodness-of-fit}

<!--chapter:end:goodness-of-fit.Rmd-->

# Linear Regression

## Learning Objectives {-#objectives-linear-regression}

1. Explain what is meant by response and explanatory variables.
2. State the simple regression model (with a single explanatory variable).
3. Derive the least squares estimates of the slope and intercept parameters in a simple linear regression model.
4. Use `R` to fit a simple linear regression model to a data set and interpret the output.
  - Perform statistical inference on the slope parameter.
  - Describe the use of measures of goodness of fit of a linear regression model.
  - Use a fitted linear relationship to predict a mean response or an individual response with confidence limits.
  - Use residuals to check the suitability and validity of a linear regression model.
5. State the multiple linear regression model (with several explanatory variables).
6. Use `R` to fit a multiple linear regression model to a data set and interpret the output.
7. Use measures of model fit to select an appropriate set of explanatory variables.

## Theory {-#theory-linear-regression}

## `R` Practice {-#practice-linear-regression}

<!--chapter:end:linear-regression.Rmd-->

# Generalised Linear Models

## Learning Objectives {-#objectives-glm}

1. Define an exponential family of distributions. Show that the following distributions may be written in this form: binomial, Poisson, exponential, gamma, normal.
2. State the mean and variance for an exponential family, and define the variance function and the scale parameter. Derive these quantities for the distributions above.
3. Explain what is meant by the link function and the canonical link function, referring to the distributions above.
4. Explain what is meant by a variable, a factor taking categorical values and an interaction term. Define the linear predictor, illustrating its form for simple models, including polynomial models and models involving factors.
5. Define the deviance and scaled deviance and state how the parameters of a generalised linear model may be estimated. Describe how a suitable model may be chosen by using an analysis of deviance and by examining the significance of the parameters.
6. Define the Pearson and deviance residuals and describe how they may be used.
7. Apply statistical tests to determine the acceptability of a fitted model: Pearson’s chi-square test and the likelihood ratio test
8. Fit a generalised linear model to a data set and interpret the output.

## Theory {-#theory-glm}

## `R` Practice {-#practice-glm}

<!--chapter:end:glm.Rmd-->

# Bayesian Statistics

## Learning Objectives {-#objectives-bayesian-stats}

1. Use Bayes’ theorem to calculate simple conditional probabilities.
2. Explain what is meant by a prior distribution, a posterior distribution and a conjugate prior distribution.
3. Derive the posterior distribution for a parameter in simple cases.
4. Explain what is meant by a loss function.
5. Use simple loss functions to derive Bayesian estimates of parameters.
6. Explain what is meant by the credibility premium formula and describe the role played by the credibility factor.
7. Explain the Bayesian approach to credibility theory and use it to derive credibility premiums in simple cases.
8. Explain the empirical Bayes approach to credibility theory and use it to derive credibility premiums in simple cases.
9. Explain the differences between the two approaches and state the assumptions underlying each of them.

## Theory {-#theory-bayesian-stats}

## `R` Practice {-#practice-bayesian-stats}

<!--chapter:end:bayesian-stats.Rmd-->

